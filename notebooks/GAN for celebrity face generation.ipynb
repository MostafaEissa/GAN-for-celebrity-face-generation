{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN for celebrity face generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my implementation of [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) on celebrity face generation using GANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model the we will use the same dataset used in the original tutorial. It can be downloaded from this [link](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). If the previous link does not work, you can download the data from [archive.org](https://archive.org/details/celeba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileroot = '../data'\n",
    "device = \"cuda\"\n",
    "image_size = 64\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = dset.ImageFolder(fileroot, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now visualize some training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-178162c457ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m plt.imshow(np.transpose(vutils.make_grid(\n\u001b[0m\u001b[0;32m      5\u001b[0m     sample_batch[0].to(device), padding=2, normalize=True).cpu(),\n\u001b[0;32m      6\u001b[0m     (1,2,0)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vutils' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(\n",
    "    sample_batch[0].to(device), padding=2, normalize=True).cpu(),\n",
    "    (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
